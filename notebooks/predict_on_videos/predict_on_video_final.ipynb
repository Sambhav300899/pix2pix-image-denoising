{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638ae448-4bab-42dc-88f4-c04922a82216",
   "metadata": {},
   "source": [
    "## RESULTS GENERATED ON A GTX GeForce 1060 6gb version (no fp16 support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b132565-ecc2-4824-9926-9db2e2b4d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17fc622-662f-4067-9ad2-2499c9462d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pix2pix\n",
    "import cv2\n",
    "import time\n",
    "from pix2pix import models\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torch2trt import torch2trt\n",
    "from pix2pix import config\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4f28e3-c674-4103-93bc-635e7b080262",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1221acc2-deaa-469b-b605-317b0c4ed8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = 'videos/input_video_gt.mp4'\n",
    "noisy_path = 'videos/input_video_noisy.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ff0d32-02f3-4a7c-8912-6c9d0a57f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class img_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs):\n",
    "        self.imgs = imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.to_list()\n",
    "        \n",
    "        inp = torch.Tensor(self.imgs[idx])\n",
    "        inp = (inp / (255 / 2)) - 1\n",
    "        inp = inp.permute((2, 0, 1))\n",
    "        \n",
    "        return inp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ca9304-789f-4715-a832-4446689b8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_as_trt(model_state_dict_path, max_bs, num_init_filters):\n",
    "    model_param_dict = dict(input_nc=3, output_nc=3, \n",
    "                            num_init_filters=num_init_filters)\n",
    "    model = models.unet(norm_layer=torch.nn.InstanceNorm2d, **model_param_dict)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(model_state_dict_path))\n",
    "    model = model.module\n",
    "    model.eval()\n",
    "    \n",
    "    print ('number of params in model: ', sum(p.numel() for p in model.parameters()))\n",
    "    print ('converting model to trt, this will take a bit of time')\n",
    "    \n",
    "    model_trt = torch2trt(model, [torch.ones(1, 3, 256, 256).to(device)], max_batch_size=max_bs)    \n",
    "    print ('done')\n",
    "    \n",
    "    return model_trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19168159-eacd-4d6b-96d2-b9a72337263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_for_vid(vid_path):\n",
    "    vid = cv2.VideoCapture(vid_path)\n",
    "    frame_list = []\n",
    "    \n",
    "    while vid.isOpened():\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) \n",
    "    \n",
    "    vid.release()    \n",
    "    \n",
    "    return frame_list\n",
    "\n",
    "def get_metrics_save_comparison_vid(gt_path, predicted_path, noisy_path, op_save_path):\n",
    "    gt_frames = get_frames_for_vid(gt_path)\n",
    "    pred_frames = get_frames_for_vid(predicted_path)\n",
    "    noisy_frames = get_frames_for_vid(noisy_path)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    output_vid_writer = cv2.VideoWriter(op_save_path, fourcc, fps, (width * 3, height))\n",
    "        \n",
    "    # print (len(pred_frames), len(gt_frames), len(noisy_frames))\n",
    "    \n",
    "    ssim_list = []\n",
    "    psnr_list = []\n",
    "    \n",
    "    for fp, fg, fi in tqdm.tqdm(zip(pred_frames, gt_frames, noisy_frames), total = len(pred_frames)):\n",
    "        cv2.putText(fi, \"INPUT\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 255, 0], 2)\n",
    "        cv2.putText(fp, \"PREDICTED\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 255, 0], 2)\n",
    "        cv2.putText(fg, \"GROUD TRUTH\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 255, 0], 2)\n",
    "        \n",
    "        ssim_list.append(structural_similarity(fp, fg, multichannel=True, dynamic_range=255))\n",
    "        psnr_list.append(peak_signal_noise_ratio(fp, fg, data_range=255))\n",
    "        \n",
    "        combined = np.hstack([fi, fp, fg])\n",
    "        output_vid_writer.write(cv2.cvtColor(combined, cv2.COLOR_RGB2BGR))  \n",
    "        \n",
    "    output_vid_writer.release()\n",
    "    print ('comparison video written to', op_save_path)\n",
    "    \n",
    "    return np.mean(ssim_list), np.mean(psnr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639824c8-d12f-45a4-9849-5a635389dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_video(model_trt, input_vid_reader, output_vid_writer, batch_size):\n",
    "    frame_list = []\n",
    "    \n",
    "    while input_vid_reader.isOpened():\n",
    "        ret, frame = input_vid_reader.read()\n",
    "\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        frame_list.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        img_dataloader = torch.utils.data.DataLoader(img_dataset(frame_list), \n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle = False,\n",
    "                                                num_workers = 1)\n",
    "\n",
    "        preds_list = []\n",
    "    \n",
    "        for ip in tqdm.tqdm(img_dataloader, total = len(img_dataloader)):    \n",
    "            ip = ip.to(device)\n",
    "            preds = model_trt(ip).detach().cpu()\n",
    "\n",
    "            preds_list.extend(list(preds))\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    for pred in preds_list:\n",
    "        pred = ((pred + 1) / 2).permute(1, 2, 0)\n",
    "        pred = (pred.numpy() * 255).astype('uint8')\n",
    "\n",
    "        output_vid_writer.write(cv2.cvtColor(pred, cv2.COLOR_RGB2BGR))  \n",
    "    \n",
    "    output_vid_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef213fc-d2da-40a5-8288-619baaa33f43",
   "metadata": {},
   "source": [
    "# model with num_init_filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19023fbd-4973-4a7c-9fbc-a7434f3f9546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params in model:  13603328\n",
      "converting model to trt, this will take a bit of time\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "state_dict_path = '../../models/pix2pix_32_13112021_183033/checkpoints/gen_epoch_12_pix2pix_32_13112021_183033.pt'\n",
    "num_init_filters = 32\n",
    "# with max_bs > 256, I get errors when converting to a tensort model on my GPU\n",
    "max_bs = 256\n",
    "\n",
    "model = load_model_as_trt(model_state_dict_path=state_dict_path,\n",
    "          num_init_filters=num_init_filters,\n",
    "          max_bs = max_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0403fc0c-e0a9-47af-a271-82c3ed028cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:04<00:00,  2.83it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.88it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.80it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.85it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote final predicted video to videos/predicted_final_32.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:23<00:00, 63.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparison video written to videos/predicted_final_32_comparison_vid.mp4\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "benchmark_num = 5\n",
    "output_path = 'videos/predicted_final_32.mp4'\n",
    "\n",
    "for i in range(0, benchmark_num):\n",
    "    input_vid_reader = cv2.VideoCapture(noisy_path)\n",
    "    fps = input_vid_reader.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(input_vid_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(input_vid_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    output_vid_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    predict_on_video(model_trt=model, input_vid_reader=input_vid_reader, \n",
    "                     output_vid_writer=output_vid_writer, batch_size = 128)\n",
    "    end = time.time()\n",
    "\n",
    "    time_list.append(end - start)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print (f'wrote final predicted video to {output_path}')\n",
    "mean_ssim, mean_psnr = get_metrics_save_comparison_vid(gt_path=gt_path, predicted_path=output_path, noisy_path=noisy_path, op_save_path = 'videos/predicted_final_32_comparison_vid.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5e8d033-1a59-46f0-ac77-a16c19a67ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg time taken (5 runs) for a video of 1 min @ 25fps(256 pix by 256 pix): 6.360 seconds\n",
      "mean SSIM: 0.744 mean PSNR: 22.692\n"
     ]
    }
   ],
   "source": [
    "print (f'Avg time taken ({benchmark_num} runs) for a video of 1 min @ 25fps(256 pix by 256 pix): {np.mean(time_list):.3f} seconds')\n",
    "print (f'mean SSIM: {mean_ssim:.3f} mean PSNR: {mean_psnr:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0412c-f6d4-4e2b-9bb3-1517ae78deb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# model with num_init_filters = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a966c74-758f-458a-a3da-cea4f6a547af",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81bd9dcf-21e9-4f50-8e6d-03217738273a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params in model:  54404096\n",
      "converting model to trt, this will take a bit of time\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "state_dict_path = '../../models/pix2pix_64_11112021_115558/checkpoints/gen_epoch_2_pix2pix_64_11112021_115558.pt'\n",
    "num_init_filters = 64\n",
    "# with max_bs > 128, I get errors when converting to a tensort model on my GPU\n",
    "max_bs = 128\n",
    "\n",
    "model = load_model_as_trt(model_state_dict_path=state_dict_path,\n",
    "          num_init_filters=num_init_filters,\n",
    "          max_bs = max_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4a5714a-850c-4b07-a55f-0944f10d23b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.11it/s]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.12it/s]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.12it/s]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.12it/s]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote final predicted video to videos/predicted_final_64.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:24<00:00, 62.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparison video written to videos/predicted_final_64_comparison_vid.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "benchmark_num = 5\n",
    "output_path = 'videos/predicted_final_64.mp4'\n",
    "\n",
    "for i in range(0, benchmark_num):\n",
    "    input_vid_reader = cv2.VideoCapture(noisy_path)\n",
    "    fps = input_vid_reader.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(input_vid_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(input_vid_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    output_vid_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    predict_on_video(model_trt=model, input_vid_reader=input_vid_reader, \n",
    "                     output_vid_writer=output_vid_writer, batch_size = 128)\n",
    "    end = time.time()\n",
    "\n",
    "    time_list.append(end - start)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print (f'wrote final predicted video to {output_path}')\n",
    "mean_ssim, mean_psnr = get_metrics_save_comparison_vid(gt_path=gt_path, predicted_path=output_path, noisy_path=noisy_path, op_save_path = 'videos/predicted_final_64_comparison_vid.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca1099a1-8cae-4e8d-adb9-1332ae94b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg time taken (5 runs) for a video of 1 min @ 25fps(256 pix by 256 pix): 12.729 seconds\n",
      "mean SSIM: 0.739 mean PSNR: 22.543\n"
     ]
    }
   ],
   "source": [
    "print (f'Avg time taken ({benchmark_num} runs) for a video of 1 min @ 25fps(256 pix by 256 pix): {np.mean(time_list):.3f} seconds')\n",
    "print (f'mean SSIM: {mean_ssim:.3f} mean PSNR: {mean_psnr:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560ee5a-68b1-4ec1-bf20-344d305ae4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
